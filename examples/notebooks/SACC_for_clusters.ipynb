{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SACC with clusters\n",
    "The default SACC scripts in the directory above show how one can make a SACC object for a 3x2 point analysis. The constructor for a SACC object has additional fields for handling clusters. This notebook details how one can use those fields to create/load/split a SACC that has cluster information.\n",
    "\n",
    "Note: this notebook is for *stacks* of clusters. Individual cluster measurements are not yet supported by SACC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmcclintock/anaconda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sacc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracers = [] # The list to hold all tracers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster stack details\n",
    "Stacks of clusters are different from regular tracers, since they are binned not only in redshift but also by richness. In this example, we have 20 cluster stacks: 5 bins in richness and 4 tomographic bins. Since this is a tomographic analysis, each cluster stack can be associated with some number of source bins. This association is handled in later cells.\n",
    "\n",
    "The following two cells create two sets of tracers:\n",
    "1. cluster stack tracers, that hold tomographic and mass-proxy (aka richness) bin edges\n",
    "2. source galaxy tracers, that are associated with individual $\\gamma_T$ weak lensing profiles for each stack-souce tracer pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create the cluster stack tracers.\n",
    "# Clusters are split into 5 richness bins and 4 tomographic bins:\n",
    "lambda_bins = [20,30,50,80,120,180] #edges of richness bins\n",
    "# Loop over centers of tomographic bins\n",
    "for i,z in enumerate([0.3,0.5,0.7,0.9]):\n",
    "    zar=np.arange(z-0.1,z+0.1,0.001)\n",
    "    Nz=np.exp(-(z-zar)**2/(2*0.03**2))\n",
    "    # Loop over richness bins\n",
    "    for j in range(0,len(lambda_bins)-1):\n",
    "        l_min = lambda_bins[j]\n",
    "        l_max = lambda_bins[j+1]\n",
    "\n",
    "        T=sacc.Tracer(\"clusters_z%i_l%i\"%(i,j),\"spin0\",zar,Nz,exp_sample=\"clusters\", \n",
    "                      Mproxy_name = \"richness\", Mproxy_min = l_min, Mproxy_max = l_max)\n",
    "        tracers.append(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomographic LSST source galaxies with 4 redshift bins\n",
    "for i,z in enumerate([0.5,0.7,0.9,1.1]):\n",
    "    zar=np.arange(z-0.1,z+0.1,0.001)\n",
    "    Nz=np.exp(-(z-zar)**2/(2*0.025**2))\n",
    "    DNz=np.zeros((len(Nz),2))\n",
    "    ## some random shapes of Nz to marginalise over\n",
    "    DNz[:,0]=(z-zar)**2*0.01\n",
    "    DNz[:,0]-=DNz[:,0].mean()\n",
    "    DNz[:,1]=(z-zar)**3*0.01\n",
    "    DNz[:,1]-=DNz[:,1].mean()\n",
    "    T=sacc.Tracer(\"lsst_sources_%i\"%i,\"spin2\",zar,Nz,exp_sample=\"lsst_sources\",\n",
    "                               DNz=DNz)\n",
    "    tracers.append(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data vectors and binning\n",
    "The SACC holds data vectors and binning information. In this example, we have binning for cluster number counts as well as binning for cluster-source lensing profiles. Both are created in the following cell, as well as the binning information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have 10 radial bins for cluster weak lensing\n",
    "# Note that the \"radial bins\" can be actual distances or angles on the sky\n",
    "rvals=np.logspace(np.log10(0.5), np.log10(3), 10)\n",
    "Ntracer=len(tracers)\n",
    "#These lists will hold the information to create the \"binning\" object, which\n",
    "#contains all information for the projected bins on the sky we are\n",
    "#working with.\n",
    "type,bins,t1,q1,t2,q2,val,err=[],[],[],[],[],[],[],[]\n",
    "#Loop over all tracers\n",
    "for t1i in range(Ntracer):\n",
    "    # If the tracer is a cluster stack, we are interested in\n",
    "    # the number counts as an observable.\n",
    "    if tracers[t1i].is_CL():\n",
    "        type.append('+N') #Number counts\n",
    "        bins.append(-1.)  #counts have no spatial bin value\n",
    "        ## We refer to tracers by their index\n",
    "        t1.append(t1i)\n",
    "        t2.append(-1) #There is no paired tracer\n",
    "        ## Here we have cluster number counts\n",
    "        q1.append('S')\n",
    "        q2.append('0')\n",
    "        ## values and errors\n",
    "        ## Number of clusters is the index, and the error is the sqrt.\n",
    "        val.append(t1i+1)\n",
    "        err.append(np.sqrt(float(t1i+1)))\n",
    "\n",
    "    # Loop over all other tracers\n",
    "    for t2i in range(t1i+1,Ntracer):\n",
    "        # Clusters can pair with all the lensing tracers (i.e. the galaxy tomographic bins)\n",
    "        if tracers[t1i].is_CL() and tracers[t2i].is_WL():\n",
    "            # Loop over radial bins\n",
    "            for r in rvals:\n",
    "                ## we have configuration space measurement\n",
    "                type.append('+R')\n",
    "                ## at this nominal rbins\n",
    "                bins.append(r)\n",
    "                ## We refer to tracers by their index\n",
    "                t1.append(t1i)\n",
    "                t2.append(t2i)\n",
    "                ## Here we have density-shear cross-correlations\n",
    "                q1.append('S')\n",
    "                q2.append('E')\n",
    "                ## values and errors\n",
    "                val.append(np.random.uniform(0,10))\n",
    "                err.append(np.random.uniform(1,2))\n",
    "\n",
    "# Create the binning object\n",
    "binning=sacc.Binning(type,bins,t1,q1,t2,q2)\n",
    "# As well as the mean vector object\n",
    "mean=sacc.MeanVec(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance matrices\n",
    "Finally, the SACC object holds a covariance matrix between all of the data we use. We will use ell_block_diagonal where everything is coupled across tracers/redshifts at the same ell but not across ell with fixed 10% off-diagonal elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to add a covariance matrix. We will use ell_block_diagonal mode,\n",
    "## even though in real space cluster lensing is NOT block diagonal.\n",
    "## This is just for illustrative purposes and isn't realistic, since\n",
    "## in reality a real space covariance matrix will be the 'dense' mode.\n",
    "Np=binning.size()\n",
    "cov=np.zeros((Np,Np))\n",
    "#Loop over all observable bins\n",
    "for i in range(Np):\n",
    "    for j in range(i,Np):\n",
    "        #If the observable bin is a number count,\n",
    "        #then assume Poisson error: Var(N) = N\n",
    "        if binning.binar['type'][i] == b'+N':\n",
    "            if i == j:\n",
    "                cov[i,i] = err[i]*err[i]\n",
    "        #The observable is a real-space lensing bin.\n",
    "        #If this is between two different bins, then\n",
    "        #reduce the covariance by a factor of 10.\n",
    "        if binning.binar['type'][i] == b'+R':\n",
    "            cov[i,j] = err[i]*err[j]\n",
    "            if i != j:\n",
    "                cov[i,j] /= 10.\n",
    "            cov[j,i] = cov[i,j]\n",
    "\n",
    "#Create a precision matrix out of the covariance.\n",
    "precision=sacc.Precision(cov, \"ell_block_diagonal\", is_covariance=True, binning=binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Meta information:\n",
      "   Creator : McGyver\n",
      "   Project : Victory\n",
      "--------------------------------\n",
      " EXP_SAMPLE: lsst_sources\n",
      "       Tomographic sample #0: <z>=0.50\n",
      "       Tomographic sample #1: <z>=0.70\n",
      "       Tomographic sample #2: <z>=0.90\n",
      "       Tomographic sample #3: <z>=1.10\n",
      " EXP_SAMPLE: clusters\n",
      "       Tomographic sample #0: <z>=0.30\n",
      "       Tomographic sample #1: <z>=0.30\n",
      "       Tomographic sample #2: <z>=0.30\n",
      "       Tomographic sample #3: <z>=0.30\n",
      "       Tomographic sample #4: <z>=0.30\n",
      "       Tomographic sample #5: <z>=0.50\n",
      "       Tomographic sample #6: <z>=0.50\n",
      "       Tomographic sample #7: <z>=0.50\n",
      "       Tomographic sample #8: <z>=0.50\n",
      "       Tomographic sample #9: <z>=0.50\n",
      "       Tomographic sample #10: <z>=0.70\n",
      "       Tomographic sample #11: <z>=0.70\n",
      "       Tomographic sample #12: <z>=0.70\n",
      "       Tomographic sample #13: <z>=0.70\n",
      "       Tomographic sample #14: <z>=0.70\n",
      "       Tomographic sample #15: <z>=0.90\n",
      "       Tomographic sample #16: <z>=0.90\n",
      "       Tomographic sample #17: <z>=0.90\n",
      "       Tomographic sample #18: <z>=0.90\n",
      "       Tomographic sample #19: <z>=0.90\n",
      "--------------------------------\n",
      "Total number of points: 820\n",
      "Precision matrix type: ell_block_diagonal\n"
     ]
    }
   ],
   "source": [
    "#Save the SACC\n",
    "# Add some meta data\n",
    "meta={\"Creator\":\"McGyver\",\"Project\":\"Victory\"}\n",
    "\n",
    "# finally, create SACC object and save\n",
    "s=sacc.SACC(tracers,binning,mean,precision,meta)\n",
    "s.printInfo()\n",
    "s.saveToHDF (\"test_clusters.sacc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting\n",
    "A SACC object with cluster information can be loaded and split, just like the example SACC in the 3x2pt analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Meta information:\n",
      "   Creator : b'McGyver'\n",
      "   Project : b'Victory'\n",
      "--------------------------------\n",
      " EXP_SAMPLE: b'lsst_sources'\n",
      "       Tomographic sample #0: <z>=0.50\n",
      "       Tomographic sample #1: <z>=0.70\n",
      "       Tomographic sample #2: <z>=0.90\n",
      "       Tomographic sample #3: <z>=1.10\n",
      " EXP_SAMPLE: b'clusters'\n",
      "       Tomographic sample #0: <z>=0.30\n",
      "       Tomographic sample #1: <z>=0.30\n",
      "       Tomographic sample #2: <z>=0.30\n",
      "       Tomographic sample #3: <z>=0.30\n",
      "       Tomographic sample #4: <z>=0.30\n",
      "       Tomographic sample #5: <z>=0.50\n",
      "       Tomographic sample #6: <z>=0.50\n",
      "       Tomographic sample #7: <z>=0.50\n",
      "       Tomographic sample #8: <z>=0.50\n",
      "       Tomographic sample #9: <z>=0.50\n",
      "       Tomographic sample #10: <z>=0.70\n",
      "       Tomographic sample #11: <z>=0.70\n",
      "       Tomographic sample #12: <z>=0.70\n",
      "       Tomographic sample #13: <z>=0.70\n",
      "       Tomographic sample #14: <z>=0.70\n",
      "       Tomographic sample #15: <z>=0.90\n",
      "       Tomographic sample #16: <z>=0.90\n",
      "       Tomographic sample #17: <z>=0.90\n",
      "       Tomographic sample #18: <z>=0.90\n",
      "       Tomographic sample #19: <z>=0.90\n",
      "--------------------------------\n",
      "Total number of points: 820\n",
      "Precision matrix type: ell_block_diagonal\n"
     ]
    }
   ],
   "source": [
    "s=sacc.SACC.loadFromHDF(\"test_clusters.sacc\")\n",
    "s.printInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision matrix, first 10 colums:\n",
      "1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 \n",
      "0.00000 0.39706 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 \n",
      "0.00000 0.00000 0.65478 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 \n",
      "0.00000 0.00000 0.00000 0.37748 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 \n",
      "0.00000 0.00000 0.00000 0.00000 0.44082 0.00000 0.00000 0.00000 0.00000 0.00000 \n",
      "0.00000 0.00000 0.00000 0.00000 0.00000 0.37776 0.00000 0.00000 0.00000 0.00000 \n",
      "0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.27570 0.00000 0.00000 0.00000 \n",
      "0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.55032 0.00000 0.00000 \n",
      "0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.31635 0.00000 \n",
      "0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.65148 \n"
     ]
    }
   ],
   "source": [
    "print (\"Precision matrix, first 10 colums:\")\n",
    "## This will invert matrix from covariance on the fly\n",
    "m=s.precision.precisionMatrix()\n",
    "Ncol = 10\n",
    "for i in range(Ncol):\n",
    "    for j in range(Ncol):\n",
    "        print ('%5.5f '%m[i,j],end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the SACC\n",
    "s.mean.saveToHDFFile(\"cluster_split.mean.sacc\")\n",
    "s.precision.saveToHDFFile(\"cluster_split.precision.sacc\")\n",
    "s.saveToHDF(\"cluster_split.main.sacc\",save_mean=False, mean_filename=\"cluster_split.mean.sacc\",\n",
    "            save_precision=False, precision_filename=\"cluster_split.precision.sacc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Meta information:\n",
      "   Creator : b'McGyver'\n",
      "   Project : b'Victory'\n",
      "--------------------------------\n",
      " EXP_SAMPLE: b\"b'clusters'\"\n",
      "       Tomographic sample #0: <z>=0.30\n",
      "       Tomographic sample #1: <z>=0.30\n",
      "       Tomographic sample #2: <z>=0.30\n",
      "       Tomographic sample #3: <z>=0.30\n",
      "       Tomographic sample #4: <z>=0.30\n",
      "       Tomographic sample #5: <z>=0.50\n",
      "       Tomographic sample #6: <z>=0.50\n",
      "       Tomographic sample #7: <z>=0.50\n",
      "       Tomographic sample #8: <z>=0.50\n",
      "       Tomographic sample #9: <z>=0.50\n",
      "       Tomographic sample #10: <z>=0.70\n",
      "       Tomographic sample #11: <z>=0.70\n",
      "       Tomographic sample #12: <z>=0.70\n",
      "       Tomographic sample #13: <z>=0.70\n",
      "       Tomographic sample #14: <z>=0.70\n",
      "       Tomographic sample #15: <z>=0.90\n",
      "       Tomographic sample #16: <z>=0.90\n",
      "       Tomographic sample #17: <z>=0.90\n",
      "       Tomographic sample #18: <z>=0.90\n",
      "       Tomographic sample #19: <z>=0.90\n",
      " EXP_SAMPLE: b\"b'lsst_sources'\"\n",
      "       Tomographic sample #0: <z>=0.50\n",
      "       Tomographic sample #1: <z>=0.70\n",
      "       Tomographic sample #2: <z>=0.90\n",
      "       Tomographic sample #3: <z>=1.10\n",
      "--------------------------------\n",
      "Total number of points: 820\n",
      "Precision matrix type: ell_block_diagonal\n"
     ]
    }
   ],
   "source": [
    "#We can now reload, and the SACC will be reconsituted from three files.\n",
    "sn=sacc.SACC.loadFromHDF(\"cluster_split.main.sacc\")\n",
    "sn.printInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "100\n",
      "(0, -1, b'+N', None, None)\n",
      "(0, 20, b'+R', array([0.5       , 0.61014247, 0.74454767, 0.9085603 , 1.1087024 ,\n",
      "       1.3529329 , 1.6509637 , 2.014646  , 2.4584422 , 3.        ],\n",
      "      dtype=float32), array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]))\n"
     ]
    }
   ],
   "source": [
    "#This is an example of how to call the sortTracers() function\n",
    "#which returns information about the kinds of measurements we have\n",
    "print(len(sn.tracers))\n",
    "s2 = sn.sortTracers()\n",
    "print(len(s2)) #Wrong. Should be 100 long\n",
    "print(s2[0])\n",
    "print(s2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
